# üè† Sistema de Meta-Classifica√ß√£o de Vulnerabilidade Social

![Status](https://img.shields.io/badge/status-operational-brightgreen)
![Python](https://img.shields.io/badge/python-3.8+-blue)
![ML](https://img.shields.io/badge/ML-99.15%25%20accuracy-success)
![LLM](https://img.shields.io/badge/LLM-Google%20Gemini-purple)

Sistema inteligente para classifica√ß√£o e an√°lise de vulnerabilidade social utilizando Machine Learning e LLMs.

## ‚ú® Caracter√≠sticas


## üöÄ In√≠cio R√°pido

### 1. Instala√ß√£o

```bash
# Clone o reposit√≥rio
git clone https://github.com/Ageubr/meta-classificador.git
cd meta-classificador

# Instale as depend√™ncias
pip install -r requirements.txt

# Configure a API Gemini (gratuita)
echo "GEMINI_API_KEY=sua_chave_aqui" > .env
echo "GEMINI_MODEL=gemini-2.0-flash" >> .env
```

### 2. Inicie o Sistema

```bash
# Inicie a API
python src/api.py
```

### 3. Acesse a Interface

Abra seu navegador em: **http://localhost:8000**

Ou acesse a documenta√ß√£o da API: **http://localhost:8000/docs**

## üéØ Como Usar

### Interface Web

1. Acesse http://localhost:8000
2. Preencha os dados da fam√≠lia no formul√°rio
3. Clique em "ü§ñ Analisar Vulnerabilidade" para predi√ß√£o ML
4. Clique em "üß† An√°lise com IA" para an√°lise qualitativa detalhada

### API REST

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"idade_responsavel": 28, ...}'
```

## üì° Endpoints

| M√©todo | Endpoint | Descri√ß√£o |
|--------|----------|-----------|
| GET | `/` | Interface web |
# Meta-Classificador de Vulnerabilidade Social

Projeto para classifica√ß√£o e an√°lise de vulnerabilidade social usando modelos de Machine Learning (Random Forest, XGBoost) e an√°lise interpretativa com LLMs.

**Objetivo:** prover predi√ß√µes automatizadas e relat√≥rios interpret√°veis para apoiar gest√£o p√∫blica e programas sociais.

**Status:** c√≥digo em desenvolvimento ‚Äî leia as instru√ß√µes de uso e vari√°veis de ambiente antes de executar.

**Principais arquivos:** `src/api.py`, `src/preprocessamento.py`, `src/modelos_ml.py`, `frontend/` e `outputs/modelos/`.

**Requisitos:**

**Instala√ß√£o r√°pida**

1. Clone o reposit√≥rio e crie um ambiente virtual:

```bash
git clone https://github.com/Ageubr/meta-classificador.git
cd meta-classificador
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

2. Configure vari√°veis de ambiente (opcional para funcionalidades LLM):

```bash
# Exemplo m√≠nimo no arquivo .env
GOOGLE_API_KEY=SuaChaveAqui
# Outras vari√°veis opcionais podem ser carregadas pelo c√≥digo
```

Observa√ß√£o: o projeto usa integra√ß√£o com APIs de LLM (Google Generative AI). Sem chave de API a parte de an√°lise LLM ficar√° indispon√≠vel, mas endpoints ML continuam funcionais se os modelos estiverem presentes em `outputs/modelos/`.

**Como executar**


```bash
./iniciar.sh
```


```bash
python src/api.py
# ou (alternativa) uvicorn src.api:app --reload --host 0.0.0.0 --port 8000
```


```bash
./run_frontend.sh
```

Ap√≥s iniciar a API, abra `http://localhost:8000/` no navegador. A documenta√ß√£o interativa da API fica em `http://localhost:8000/docs`.

**Principais endpoints**

Consulte `src/api.py` para documenta√ß√£o mais detalhada das entradas esperadas (modelos Pydantic est√£o definidos l√°).

**Estrutura do reposit√≥rio (resumo)**

**Testes**

Execute a su√≠te de testes com:

```bash
pytest
```

**Contribui√ß√£o**

Pull requests s√£o bem-vindos. Para grandes mudan√ßas, abra uma issue primeiro descrevendo a proposta.

**Scripts √∫teis**

**Licen√ßa**

# üè† Meta-Classificador de Vulnerabilidade Social

Projeto para classifica√ß√£o e an√°lise de vulnerabilidade social que combina modelos de Machine Learning (Random Forest, XGBoost) com uma camada interpretativa baseada em LLM (Google Gemini). O objetivo √© oferecer predi√ß√µes robustas e explica√ß√µes acion√°veis para suporte a pol√≠ticas p√∫blicas e programas sociais.

---

**Este README foi escrito seguindo o comportamento do c√≥digo presente em `src/` (principalmente `src/api.py` e `src/meta_classificador_llm.py`).**

## Conceito e objetivo

- Conceito: o sistema opera em duas camadas complementares ‚Äî uma camada ML (modelos supervisados que classificam n√≠veis de vulnerabilidade) e uma camada LLM (um "meta-classificador" que recebe os dados e as sa√≠das dos modelos para gerar justificativas, fatores de risco e recomenda√ß√µes).
- Objetivo: identificar fam√≠lias/munic√≠pios em situa√ß√£o de vulnerabilidade, gerar an√°lises interpret√°veis e facilitar integra√ß√£o via API REST.

## Principais caracter√≠sticas (alinhado ao c√≥digo)

- Predi√ß√£o multi-modelo: Random Forest e XGBoost (arquivos esperados em `outputs/modelos/`).
- Meta-classifica√ß√£o por LLM: integra√ß√£o com Google Gemini usando vari√°vel de ambiente `GEMINI_API_KEY` (opcional).
- Endpoints REST com FastAPI (arquivo `src/api.py`).
- Processamento em lote e agrega√ß√£o por munic√≠pio (`/data/process`, `/data/analyze-municipality`).
- Frontend est√°tico servido pela API (pasta `frontend/`).
- Scripts auxiliares: `iniciar.sh`, `run_frontend.sh`.

## Requisitos

- Python 3.10+ recomendado
- Depend√™ncias listadas em `requirements.txt` (pandas, scikit-learn, xgboost, google-generativeai, fastapi, uvicorn, python-dotenv, joblib, etc.)

## Vari√°veis de ambiente importantes

- `GEMINI_API_KEY` ‚Äî chave da API Google Generative AI usada pelo `MetaClassificadorLLM` (nome usado no c√≥digo: `GEMINI_API_KEY`).
- `GEMINI_MODEL` ‚Äî (opcional) modelo Gemini a ser usado (ex.: `gemini-2.0-flash`).

Observa√ß√£o pr√°tica: alguns scripts no reposit√≥rio (ex.: `iniciar.sh`) referenciam `GOOGLE_API_KEY`; para evitar problemas locais, voc√™ pode definir ambas (`GEMINI_API_KEY` e `GOOGLE_API_KEY`) no seu `.env` se quiser usar os scripts.

## Nomes e formato esperado dos arquivos de modelo

A API tenta carregar arquivos em `outputs/modelos/`:

- `random_forest_vulnerabilidade.pkl`
- `xgboost_vulnerabilidade.pkl`

Formato esperado (ao salvar com `joblib.dump`): um dicion√°rio com chaves t√≠picas:

- `modelo`: o objeto do modelo (estimator) ‚Äî usado por `api.py` e por `MetaClassificadorLLM`.
- `scaler`: (opcional, usado pelo `MetaClassificadorLLM`) scaler/transfomer para aplicar √†s features antes de predizer.
- `features`: (opcional) lista de nomes das features usadas no modelo ‚Äî usada em `api.py` para mostrar import√¢ncias.
- `metricas`: (opcional) m√©tricas do modelo (accuracy, f1, etc.)

Exemplo de estrutura ao salvar:

```python
joblib.dump({'modelo': clf, 'scaler': scaler, 'features': feature_names, 'metricas': metrics}, 'outputs/modelos/random_forest_vulnerabilidade.pkl')
```

Se os arquivos n√£o estiverem presentes, a API inicializa, mas alguns endpoints retornar√£o status de "n√£o carregado".

## Como executar (local)

1. Crie ambiente e instale depend√™ncias:

```bash
git clone https://github.com/Ageubr/meta-classificador.git
cd meta-classificador
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

2. Configure o `.env` (opcional, necess√°rio para LLM):

```bash
# Exemplo m√≠nimo
GEMINI_API_KEY=SuaChaveAqui
GEMINI_MODEL=gemini-2.0-flash
# (opcional) GOOGLE_API_KEY=SuaChaveAqui  # para compatibilidade com scripts
```

3. Inicie a API:

```bash
# Usando o script
./iniciar.sh
# Ou diretamente
python src/api.py
# Alternativamente (uvicorn):
# uvicorn src.api:app --reload --host 0.0.0.0 --port 8000
```

4. Acesse:

- Frontend: `http://localhost:8000/`
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

## Endpoints principais (resumo e exemplos)

### 1) `GET /health`
Retorna o status geral e se os modelos foram carregados. Exemplo de resposta:

```json
{
  "status": "healthy",
  "models": {
    "random_forest": true,
    "xgboost": true,
    "meta_classificador": true
  },
  "timestamp": "2025-11-26T..."
}
```

### 2) `POST /predict`
Predi√ß√£o ML para um √∫nico registro. O corpo deve seguir o Pydantic `DadosFamilia` definido em `src/api.py` ‚Äî campos essenciais:

- `idade_responsavel` (int)
- `numero_membros` (int)
- `criancas` (int)
- `idosos` (int)
- `renda_per_capita` (float)
- `pessoas_trabalhando` (int)
- `possui_agua_encanada`, `possui_esgoto`, `possui_coleta_lixo`, `possui_energia` (bool)
- `material_parede`, `material_teto` (str)
- `comodos` (int)
- `possui_banheiro` (bool)
- `tempo_residencia` (int, meses)
- `recebe_bolsa_familia` (bool)
- `valor_bolsa_familia` (float)
- `nivel_escolaridade` (str)
- `situacao_trabalho` (str)

Exemplo de request:

```json
{
  "idade_responsavel": 35,
  "numero_membros": 4,
  "criancas": 1,
  "idosos": 0,
  "renda_per_capita": 250.0,
  "pessoas_trabalhando": 1,
  "possui_agua_encanada": true,
  "possui_esgoto": false,
  "possui_coleta_lixo": true,
  "possui_energia": true,
  "material_parede": "Alvenaria",
  "material_teto": "Telha",
  "comodos": 3,
  "possui_banheiro": true,
  "tempo_residencia": 36,
  "recebe_bolsa_familia": false,
  "valor_bolsa_familia": 0.0,
  "nivel_escolaridade": "Fundamental",
  "situacao_trabalho": "Informal"
}
```

Exemplo de resposta (modelo `PredictionResponse` em `src/api.py`):

```json
{
  "vulnerabilidade_rf": "M√©dia",
  "vulnerabilidade_xgb": "Alta",
  "probabilidade_rf": {"Baixa": 0.1, "M√©dia": 0.7, "Alta": 0.2},
  "probabilidade_xgb": {"Baixa": 0.05, "M√©dia": 0.25, "Alta": 0.7},
  "features_importantes": {"renda_per_capita": 0.35, "idade": 0.25},
  "timestamp": "2025-11-26T..."
}
```

> Observa√ß√£o: o `api.py` mapeia alguns campos de entrada para os nomes de feature esperados pelo preprocessamento (ex.: `idade_responsavel` ‚Üí `idade`, `numero_membros` ‚Üí `qtd_pessoas_familia`, etc.).

### 3) `POST /analyze`
Executa predi√ß√µes ML e, se configurado, chama o meta-classificador LLM para gerar uma an√°lise interpretativa. Resposta inclui `analise_llm` com o texto gerado (ou mensagem informando indisponibilidade se a chave n√£o estiver configurada).

Exemplo (resumo):

```json
{
  "predicao_rf": "M√©dia",
  "predicao_xgb": "Alta",
  "probabilidades_rf": {"Baixa": 0.1, "M√©dia": 0.7, "Alta": 0.2},
  "probabilidades_xgb": {"Baixa": 0.05, "M√©dia": 0.25, "Alta": 0.7},
  "analise_llm": "<texto gerado pela LLM com justificativa e recomenda√ß√µes>",
  "timestamp": "2025-11-26T..."
}
```

### 4) Endpoints de processamento em lote
- `GET /data/files` ‚Äî lista arquivos CSV em `data/`.
- `GET /data/process?filepath=<caminho>` ‚Äî processa um CSV e aplica predi√ß√µes ML.
- `GET /data/analyze-municipality?filepath=<caminho>` ‚Äî agrega resultados por munic√≠pio e, se dispon√≠vel, gera an√°lise LLM consolidada.

Consulte `src/api.py` para par√¢metros adicionais (por exemplo `max_rows`).

## Detalhes t√©cnicos √∫teis (para desenvolvedores)

- O `startup_event` em `src/api.py` tenta carregar os modelos em `outputs/modelos/` usando `joblib` ao inicializar a API. Se os arquivos n√£o existirem, a API ainda roda, mas endpoints que dependem dos modelos devolver√£o erro de servi√ßo (`503`).
- O `MetaClassificadorLLM` (arquivo `src/meta_classificador_llm.py`) busca `GEMINI_API_KEY` e s√≥ tenta chamar a API Gemini se o pacote `google.generativeai` estiver instalado e a chave estiver dispon√≠vel.
- A fun√ß√£o `predizer_modelos_ml` no meta-classificador espera um conjunto de features nomeadas (lista definida no c√≥digo). Se voc√™ treinar novos modelos, garanta que o conjunto de features e os scalers usados sejam consistentes com o que o c√≥digo espera.

Features esperadas (exemplo retirado do c√≥digo):

```
['idade', 'escolaridade', 'renda_per_capita', 'qtd_pessoas_familia',
 'possui_deficiencia', 'situacao_trabalho', 'tipo_moradia',
 'acesso_agua', 'acesso_esgoto', 'vulnerabilidade_idade',
 'infraestrutura_adequada', 'escolaridade_baixa',
 'situacao_trabalho_precaria', 'superlotacao', 'recebe_bolsa_familia']
```

## Boas pr√°ticas e privacidade

- N√£o comite chaves de API no reposit√≥rio. Use `.env` e `.gitignore`.
- Ao processar dados pessoais, assegure anonimiza√ß√£o e conformidade com a legisla√ß√£o aplic√°vel.

## Testes

- H√° testes em `tests/`. Execute com `pytest`.

## Pr√≥ximos passos que posso ajudar a implementar

- Incluir exemplos de `response` mais detalhados para cada endpoint;
- Adicionar um exemplo de script para treinar e salvar modelos no formato esperado;
- Adicionar um `Dockerfile` e `docker-compose.yml` para deploy local.

---

Se quiser, atualizo o `iniciar.sh` para usar `GEMINI_API_KEY` (atualmente o script referencia `GOOGLE_API_KEY`) e adiciono um exemplo de como salvar modelos (`joblib.dump`) com a estrutura esperada ‚Äî quer que eu fa√ßa isso agora?

## Informa√ß√µes do sistema (resumo das notas do desenvolvedor)

Estas informa√ß√µes foram fornecidas pela equipe de desenvolvimento e refletem decis√µes de modelagem, par√¢metros de treino e comportamento do sistema:

- Dados: o sistema processa dados REAIS do governo (Cad√önico) para gerar features e alimentar os modelos.
- Classifica√ß√£o em 4 n√≠veis (mapeamento a partir de um score):
  - Score < -0.5 ‚Üí **Baixa**
  - -0.5 a 0 ‚Üí **M√©dia**
  - 0 a 0.5 ‚Üí **Alta**
  - Score > 0.5 ‚Üí **Muito Alta**

- Treinamento Random Forest (configura√ß√£o utilizada):
  - 100 √°rvores de decis√£o
  - Split: 80% treino / 20% teste
  - Valida√ß√£o: cross-validation com 5 folds
  - Objetivo: aprender padr√µes nos dados para prever vulnerabilidade sem precisar calcular score manualmente

- Configura√ß√£o e diferen√ßas entre modelos (Random Forest vs XGBoost):
  - Random Forest
    - M√©todo: Bagging (√°rvores paralelas independentes)
    - 100 √°rvores constru√≠das ao mesmo tempo
    - Cada √°rvore vota; a maioria decide a classe final
    - Vantagem: mais robusto e menos propenso a overfitting em muitos cen√°rios
  - XGBoost (Extreme Gradient Boosting)
    - M√©todo: Boosting (√°rvores sequenciais)
    - 100 √°rvores constru√≠das em sequ√™ncia
    - Cada nova √°rvore corrige erros das anteriores
    - Otimiza√ß√£o via gradient descent
    - Par√¢metros t√≠picos: learning_rate = 0.1, early stopping (para interromper quando n√£o houver melhora)

- Features mais importantes identificadas (exemplos):
  - `renda_per_capita`
  - `idade`
  - `nivel_escolaridade` / `escolaridade`
  - `acesso_agua` / `acesso_esgoto` / infraestrutura
  - `situacao_trabalho`

- Comportamento: o modelo fornece predi√ß√µes diretas (classes) baseadas nas features, dispensando c√°lculo manual do score para classificar fam√≠lias.

- Comandos √∫teis (scripts existentes):
  - `./iniciar.sh` ‚Äî iniciar o sistema (API + verifica√ß√µes)
  - `./status.sh` ‚Äî checar status dos servi√ßos/modelos

- Checklist fornecido pela equipe (status do projeto):
  - ‚úÖ Frontend rodando (`index.html`, `data-viewer.html`)
  - ‚úÖ API com Random Forest + XGBoost
  - ‚úÖ Meta-classificador LLM (Google Gemini)
  - ‚úÖ An√°lise individual e em lote por munic√≠pio
  - ‚úÖ C√≥digo limpo e documentado
  - ‚úÖ Scripts √∫teis (`iniciar.sh`, `status.sh`)
